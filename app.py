# -*- coding: utf-8 -*-
# app.py
# ×§×•×‘×¥ Flask ×¨××©×™ ×”××›×™×œ ××ª ×œ×•×’×™×§×ª ×”×—×™×¤×•×© ×”×¡×× ×˜×™ ×•×”×¤××–×™.

import os
import re
import unicodedata
import copy
from dataclasses import dataclass
from typing import List, Optional, Dict, Any

# ×™×™×‘×•× ×¡×¤×¨×™×•×ª Flask ×•-Jinja2
from flask import Flask, render_template, request, jsonify

# ×™×™×‘×•× ×¡×¤×¨×™×•×ª ×”-AI ×•×”×—×™×¤×•×©
from rapidfuzz import fuzz
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document

# ============================================
# ×”×’×“×¨×•×ª Flask ×•×˜×¢×™× ×ª × ×ª×•× ×™× ×’×œ×•×‘×œ×™×™×
# ============================================

app = Flask(__name__)
# ×—×©×•×‘: ×××¤×©×¨ ×ª×¦×•×’×ª ×¢×‘×¨×™×ª ×ª×§×™× ×” ×‘×ª×’×•×‘×•×ª ×”-JSON
app.config['JSON_AS_ASCII'] = False 

# ×”×’×“×¨×ª ××©×ª× ×™× ×’×œ×•×‘×œ×™×™× (×™×˜×¢× ×• ×¤×¢× ××—×ª)
FAQ_PATH = "faq.txt" # ×§×•×‘×¥ ×–×” ×¦×¨×™×š ×œ×”×™×•×ª ×‘×ª×™×§×™×™×ª ×”×‘×¡×™×¡
faq_items = []
faq_store = None
embeddings = None
embeddings_ready = False
openai_api_key = None

# ×”×’×“×¨×ª ×©××œ×•×ª × ×¤×•×¦×•×ª ×œ×”×¦×’×” ×‘×“×£ ×”×‘×™×ª
POPULAR_FAQ_LIST = [
    "××™×š ××•×¡×™×¤×™× ××©×ª××© ×—×“×© ×‘××ª×¨ ××™×™×¦×’×™×.",
    "××§×‘×œ ×”×•×“×¢×” ×©××—×“ ××• ×™×•×ª×¨ ×× ×ª×•× ×™ ×”×”×–×“×”×•×ª ×©×’×•×™×™×.",
    "××™×š ×™×•×¦×¨×™× ×§×™×¦×•×¨ ×“×¨×š ×œ××ª×¨ ××™×™×¦×’×™× ×¢×œ ×©×•×œ×—×Ÿ ×”×¢×‘×•×“×”.",
    "×¨×•×¦×” ×œ×§×‘×œ ××ª ×”×§×•×“ ×”×—×“ ×¤×¢××™ ×œ×“×•××¨ ××œ×§×˜×¨×•× ×™.",
]

# ============================================
# ××•×“×œ×™ × ×ª×•× ×™× ×•×¤×•× ×§×¦×™×•×ª ×¢×™×‘×•×“ (××”×§×•×“ ×©×œ×š)
# ============================================

@dataclass
class FAQItem:
    question: str
    variants: List[str]
    answer: str

def normalize_he(s: str) -> str:
    """×× ×¨××œ ×˜×§×¡×˜ ×¢×‘×¨×™ ×œ×—×™×¤×•×© (××•×¡×¨ × ×™×§×•×“, ×¡××œ×™×, ×××—×“ ×¨×•×•×—×™× ×•×›×•')."""
    if not s:
        return ""
    s = unicodedata.normalize("NFC", s)
    s = re.sub(r"[\u200e\u200f]", "", s)
    s = re.sub(r"[^\w\s\u0590-\u05FF]", " ", s)
    s = re.sub(r"\s+", " ", s).strip().lower()

    patterns = [
        (r"^×¨×•×¦×” ", "××™×š "),
        (r"^×× ×™ ×¨×•×¦×” ", "××™×š "),
        (r"^××¤×©×¨ ", "××™×š "),
        (r"^×‘× ×œ×™ ", "××™×š "),
        (r"^××‘×§×© ", "××™×š "),
    ]
    for p, repl in patterns:
        if re.match(p, s):
            s = re.sub(p, repl, s)
            break

    s = s.replace("×¢××“×”", "×¢××“×” ×œ××—×©×‘")
    s = s.replace("×œ×”×•×¡×™×£ ×¢××“×”", "×œ×”×•×¡×™×£ ××©×ª××© ×—×“×©")

    return s

def parse_faq_new(text: str) -> List[FAQItem]:
    """××¤×¨×§ ××ª ×§×•×‘×¥ ×”-FAQ ×œ×¤×™ ××‘× ×” ×©××œ×”/× ×™×¡×•×—×™×/×ª×©×•×‘×”."""
    items = []
    blocks = re.split(r"(?=×©××œ×”\s*:)", text)
    for b in blocks:
        b = b.strip()
        if not b:
            continue
        
        q_match = re.search(r"×©××œ×”\s*:\s*(.+)", b)
        a_match = re.search(r"(?s)×ª×©×•×‘×”\s*:\s*(.+?)(?:\n× ×™×¡×•×—×™× ×“×•××™×\s*:|\Z)", b)
        v_match = re.search(r"(?s)× ×™×¡×•×—×™× ×“×•××™×\s*:\s*(.+?)(?:\n×ª×©×•×‘×”\s*:|\Z)", b)
        
        question = q_match.group(1).strip() if q_match else ""
        answer = a_match.group(1).strip() if a_match and not v_match else "" # Added logic to prevent mixup
        
        if not a_match and not v_match:
             a_match = re.search(r"(?s)×ª×©×•×‘×”\s*:\s*(.+)", b) # Fallback for no variants
             answer = a_match.group(1).strip() if a_match else ""

        if v_match:
            # Need to re-search answer if variants were found first
            a_match = re.search(r"(?s)×ª×©×•×‘×”\s*:\s*(.+)", b)
            answer = a_match.group(1).strip() if a_match else ""
        
        variants = []
        if v_match:
            raw = v_match.group(1)
            # ××¤×¨×§ × ×™×¡×•×—×™× ×“×•××™× ×©××•×¤×™×¢×™× ×‘×©×•×¨×•×ª × ×¤×¨×“×•×ª
            variants = [s.strip(" -\t") for s in raw.split("\n") if s.strip()]

        items.append(FAQItem(question, variants, answer))
    return items

def format_answer_for_html(text: str) -> str:
    """
    (×¤×•×ª×¨ ×‘×¢×™×•×ª 2 ×•-3) ××¢×‘×“ ×˜×§×¡×˜ ×’×•×œ××™ ×œ×ª×¦×•×’×ª HTML:
    1. ××—×œ×™×£ ××¢×‘×¨×™ ×©×•×¨×” ×‘-<br>.
    2. ××“×’×™×© ×˜×§×¡×˜ ×‘×ª×•×š ×¡×•×’×¨×™×™× ××¨×•×‘×¢×™× (×›×’×•×Ÿ [×§×™×©×•×¨×™×] ××• [×©××•×ª ×˜×¤×¡×™×]) ×¢× ×¡×¤××Ÿ.
    """
    
    # 1. ×˜×™×¤×•×œ ×‘××¢×‘×¨×™ ×©×•×¨×”: ×”×—×œ×¤×ª \n ×‘-<br> (×¤×ª×¨×•×Ÿ ×‘×¢×™×” 2)
    formatted_text = text.replace('\n', '<br>')
    
    # 2. ×˜×™×¤×•×œ ×‘×˜×§×¡×˜ ×‘×ª×•×š ×¡×•×’×¨×™×™× ××¨×•×‘×¢×•×ª (×¤×ª×¨×•×Ÿ ×‘×¢×™×” 3)
    # ××—×œ×™×£ [×˜×§×¡×˜] ×‘- <span class="highlight">×˜×§×¡×˜</span>
    formatted_text = re.sub(r'\[([^\]]+)\]', r'<span class="highlight">\1</span>', formatted_text)
    
    # 3. ×˜×™×¤×•×œ ×‘×›×•×ª×¨×ª ×”××˜×-×“××˜×” ×©××•×¤×™×¢×” ×‘×ª×—×ª×™×ª ×”×ª×©×•×‘×”
    formatted_text = formatted_text.replace("--- ××˜× ×“××˜×” ---", "<hr><code>--- ××˜× ×“××˜×” ---</code>")

    return formatted_text


def search_faq(query: str) -> Dict[str, Any]:
    """××‘×¦×¢ ×—×™×¤×•×© ×¤××–×™ ×•×¡×× ×˜×™ ×•××—×–×™×¨ ××ª ×”×ª×•×¦××” ×”×˜×•×‘×” ×‘×™×•×ª×¨."""
    global faq_store, faq_items, embeddings_ready, embeddings
    nq = normalize_he(query)

    verbs = {
        "add": ["×”×•×¡×£", "×œ×”×•×¡×™×£", "×”×•×¡×¤×”", "××•×¡×™×£", "××•×¡×™×¤×™×", "×œ×¦×¨×£", "×¦×™×¨×•×£", "×¤×ª×™×—×”", "×¤×ª×™×—×ª", "×¨×™×©×•×", "×œ×”×™×¨×©×"],
        "delete": ["××—×§", "××—×™×§×”", "×œ×”×¡×™×¨", "×”×¡×¨", "×”×¡×¨×”", "×‘×™×˜×•×œ", "×œ×‘×˜×œ", "×¡×’×•×¨", "×œ×¡×’×•×¨", "×‘×™×˜×•×œ ××©×ª××©"],
        "update": ["×¢×“×›×Ÿ", "×œ×¢×“×›×Ÿ", "×¢×“×›×•×Ÿ", "×©×™× ×•×™", "×œ×©× ×•×ª", "×¢×¨×™×›×”", "×¢×¨×•×š", "×œ×ª×§×Ÿ", "×ª×™×§×•×Ÿ"]
    }
    intent = None
    for k, words in verbs.items():
        if any(w in nq for w in words):
            intent = k
            break
    
    scored = []
    for i, item in enumerate(faq_items):
        all_texts = [item.question] + item.variants
        for t in all_texts:
            score = fuzz.token_sort_ratio(nq, normalize_he(t))

            t_intent = None
            for k, words in verbs.items():
                if any(w in t for w in words):
                    t_intent = k
                    break

            if intent and t_intent and intent != t_intent:
                score -= 50
            if intent and t_intent and intent == t_intent:
                score += 25

            scored.append((score, i, t.strip(), t_intent))

    scored.sort(reverse=True, key=lambda x: x[0])
    top = scored[:5]

    best_fuzzy_score = top[0][0] if top else 0
    result_item = None
    similar_questions = []

    # ============================
    # Embeddings (×¨×§ ×× ×˜×¢×™× ×” ×”×¦×œ×™×—×”)
    # ============================
    if embeddings_ready and faq_store:
        try:
            hits = faq_store.similarity_search_with_score(nq, k=8)
        except Exception as e:
            print(f"Error during similarity search: {e}")
            hits = []

        key_words = ["×™×¤×•×™", "×›×•×—", "×”×¨×©××”", "×™×™×¦×•×’", "××™×™×¦×’", "××¢×¡×™×§", "××‘×•×˜×—"]
        boosted_hits = []

        for doc, score in hits:
            idx = doc.metadata["idx"]
            question_text = faq_items[idx].question
            text_norm = normalize_he(question_text + " " + " ".join(faq_items[idx].variants))

            for kw in key_words:
                if kw in nq and kw in text_norm:
                    score -= 0.15 # Boosting relevant results
            boosted_hits.append((doc, score))

        boosted_hits.sort(key=lambda x: x[1])
        best_embed_score = boosted_hits[0][1] if boosted_hits else 999
        
        # ×ª× ××™ ×¡×£ ×¨×œ×•×•× ×˜×™×•×ª
        if best_fuzzy_score < 55 and best_embed_score > 1.2:
             return {"success": False, "answer": "×œ× × ××¦××” ×ª×©×•×‘×”, × ×¡×” ×œ× ×¡×— ××ª ×”×©××œ×” ××—×“×©.", "similar_questions": []}

        if best_fuzzy_score >= 55:
            result_item = copy.deepcopy(faq_items[top[0][1]])
        elif boosted_hits and best_embed_score <= 1.2:
            result_item = copy.deepcopy(faq_items[boosted_hits[0][0].metadata["idx"]])
            
        if result_item:
            # ××•×¡×¤×™× ×©××œ×•×ª ×“×•××•×ª ××”-Embeddings
            similar_questions = [
                faq_items[d.metadata["idx"]].question
                for d, s in boosted_hits[1:4]
                if s <= 1.3 and faq_items[d.metadata["idx"]].question.strip() != result_item.question.strip()
            ][:3]
    
    # ×× ×”-embeddings ×œ× ×¢×‘×“×• (×‘×’×œ×œ ×©×’×™××ª ×˜×¢×™× ×”) × ×¡×ª××š ×¨×§ ×¢×œ ×¤××–×™
    elif best_fuzzy_score >= 55:
        result_item = copy.deepcopy(faq_items[top[0][1]])
        
    if not result_item:
        return {"success": False, "answer": "×œ× × ××¦××” ×ª×©×•×‘×”, × ×¡×” ×œ× ×¡×— ××ª ×”×©××œ×” ××—×“×©.", "similar_questions": []}

    # ×¢×™×¦×•×‘ ×”×ª×•×¦××” ×”×¡×•×¤×™×ª
    answer_text = result_item.answer.strip()
    
    # ×”×•×¡×¤×ª ×›×•×ª×¨×ª ××˜× ×“××˜×”
    answer_text += f"\n\n--- ××˜× ×“××˜×” ---\n××§×•×¨: faq\n×©××œ×” ××–×•×”×”: {result_item.question}"
    
    # ×¢×™×‘×•×“ ×”×ª×©×•×‘×” ×œ-HTML ×•×”×•×¡×¤×ª×” ×œ××™×œ×•×Ÿ ×”×ª×•×¦××”
    return {
        "success": True, 
        "answer_html": format_answer_for_html(answer_text), # ××¢×‘×™×¨ ××ª ×”×ª×©×•×‘×” ×”××¢×•×¦×‘×ª
        "similar_questions": similar_questions
    }

# ============================================
# ×˜×¢×™× ×” ×¨××©×•× ×™×ª ×©×œ ×”××•×“×œ×™× (×¨×¦×” ×¤×¢× ××—×ª ×‘×¢×ª ×¢×œ×™×™×ª ×”×©×¨×ª)
# ============================================

def load_initial_data():
    global faq_items, faq_store, embeddings_ready, embeddings, openai_api_key
    
    # 1. ××¤×ª×— API: Render ××›× ×™×¡ ××ª ×–×” ×›××©×ª× ×” ×¡×‘×™×‘×”
    openai_api_key = os.environ.get("OPENAI_API_KEY")
    if not openai_api_key:
        print("ğŸš¨ ××–×”×¨×”: ××©×ª× ×” OPENAI_API_KEY ×œ× ×”×•×’×“×¨. ×”×—×™×¤×•×© ×”×¡×× ×˜×™ (Embeddings) ×œ× ×™×¢×‘×•×“.")
    
    # 2. ×˜×¢×™× ×ª ×§×•×‘×¥ ×”-FAQ
    try:
        with open(FAQ_PATH, "r", encoding="utf-8") as f:
            raw_faq = f.read()
    except FileNotFoundError:
        print(f"âŒ ×©×’×™××” ×—××•×¨×”: ×§×•×‘×¥ FAQ ×œ× × ××¦× ×‘× ×ª×™×‘: {FAQ_PATH}.")
        return

    faq_items = parse_faq_new(raw_faq)
    print(f"âœ… × ×˜×¢× ×• {len(faq_items)} ×©××œ×•×ª ××”-FAQ.")
    
    # 3. ×™×¦×™×¨×ª Embeddings ×•-FAISS
    if openai_api_key and faq_items:
        try:
            # ×©×™××•×© ×‘-langchain_openai.OpenAIEmbeddings
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small", api_key=openai_api_key)
            docs = [Document(page_content=" | ".join([item.question] + item.variants), metadata={"idx": i})
                    for i, item in enumerate(faq_items)]
            faq_store = FAISS.from_documents(docs, embeddings)
            embeddings_ready = True
            print("âœ… ××™× ×“×§×¡ embeddings × ×•×¦×¨ ×‘×”×¦×œ×—×”.")
        except Exception as e:
            print(f"âŒ ×©×’×™××”: ×˜×¢×™× ×ª FAISS/Embeddings × ×›×©×œ×”: {e}. ×¨×¥ ×¨×§ ×‘××¦×‘ ×¤××–×™.")
            embeddings_ready = False

# ×”×¨×¦×ª ×”×˜×¢×™× ×” ×¤×¢× ××—×ª ×‘×¢×ª ×¢×œ×™×™×ª ×”×©×¨×ª
with app.app_context():
    load_initial_data()

# ============================================
# × ×™×ª×•×‘×™× (Routes) ×©×œ Flask
# ============================================

@app.route('/')
def index():
    # × ×™×ª×•×‘ ×œ×“×£ ×”×‘×™×ª - ××¦×™×’ ××ª ×ª×‘× ×™×ª HTML
    return render_template('index.html', popular_questions=POPULAR_FAQ_LIST)

@app.route('/search', methods=['POST'])
def search():
    # × ×™×ª×•×‘ ×œ×˜×™×¤×•×œ ×‘×‘×§×©×•×ª ×—×™×¤×•×© ×‘×××¦×¢×•×ª AJAX
    data = request.get_json()
    query = data.get('query', '')
    
    if not query:
        return jsonify({"success": False, "answer_html": "×©××™×œ×ª×” ×¨×™×§×”."})
    
    # ×”×¤×¢×œ×ª ×œ×•×’×™×§×ª ×”×—×™×¤×•×©
    result = search_faq(query)
    
    # ×”×—×–×¨×ª ×”×ª×•×¦××” ×›-JSON (×¢× ×”××¤×ª×— ×”×—×“×© answer_html)
    return jsonify(result)
